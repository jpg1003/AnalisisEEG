\apendice{Documentación técnica de programación}

\section{Introducción}

Este TFG de análisis de un conjunto de datos EEG se centra en la aplicación de técnicas avanzadas de aprendizaje automático utilizando notebooks Python. El objetivo principal es procesar y analizar datos EEG para identificar patrones y correlaciones significativas que puedan revelar comportamientos específicos en la actividad cerebral a la hora de realizar un experimento el individuo.

El propósito fundamental es aplicar modelos de aprendizaje automático para mejorar la comprensión de las señales EEG, los datos aportados por la universidad de burgos constan de unos experimentos realizados con BCI y varios voluntarios es los que estos usuarios deben visualizar una serie de imágenes compuestas por direcciones, arriba, abajo, derecha e izquierda.

Este trabajo podría tener aplicaciones importantes en tecnologías de interfaz cerebro-computadora (BCI) aplicadas a por ejemplo,  control de sillas de ruedas, control de dispositivos electrónicos, realidad virtual, videojuegos, control de robots, etc...


\section{Estructura de directorios}

La estructura de los directorios del trabajo es la siguiente:

  \begin{itemize}
  \tightlist
  \item
   \textbf{/documentación/:} Esta carpeta contiene toda la documentación relacionada con el TFG.
  \item
   \textbf{/documentación/imágenes/:} Archivo de imágenes para todo el proyecto, documentación y código.
  \item
   \textbf{/documentación/latex:} Documentación en formato latex y PDF.
  \item
   \textbf{/código:} Carpeta para archivar notebooks y datos para la ejecución del código.
  \item
   \textbf{/código/datos/:} Archivo datosEEGTotal.csv con el origen de datos.
  \item
   \textbf{/código/datos/csv/:} Archivos de datos csv auto generados tras las ejecuciones de algunos notebooks.
  \item
   \textbf{/código/notebooks:} Contiene los notebooks Jupyter y por lo tanto, el código.
  \end{itemize} 
  
  
  

\section{Manual del programador}

Este manual sera utilizado principalmente por las personas involucradas en futuros cambios, mejoras o nuevos desarrollos en el código.

Para ello, detallo las funciones de cada uno de los componentes:

  \begin{itemize}
  \tightlist
  \item
   \textbf{Notebook Principal (1.Main.ipynb):}
   
   Crea y ejecuta un entorno virtual. Coordina la ejecución de los notebooks secundarios. Es el punto de entrada para la ejecución del sistema de análisis de datos EEG.
  \item
   \textbf{Notebooks secundarios:}
   \begin{itemize}
   \tightlist
   \item
    \textbf{2.Bibliotecas.ipynb:} 
    
    En este notebooks están todas las instalaciones de bibliotecas necesarias para el sistema.
    
   \item
    \textbf{3.Importaciones.ipynb:} 
   
    Importa las bibliotecas y configuraciones necesarias para el análisis futuro de los datos.
    
   \item
    \textbf{SubirCSV.ipynb:} 
   
    Permite la subida de un archivo de datos al Notebook principal.
    
   \item
    \textbf{5.CargaDatos.ipynb:} 
   
    Realiza un análisis de los datos cargados.
    
   \item
    \textbf{6.Preprocessing.ipynb:} 
   
    Realiza la limpieza y preparación inicial de los datos EEG..
    
   \item
    \textbf{7.MachineLearning.ipynb:} : 
    
    Implementa experimentos utilizando modelos KNN, Árboles de Decisión, Random Forest con validaciones como hold-out, k-fold cross validation ... para evaluar los modelos de aprendizaje automático básico.
    
   \item
    \textbf{8.1.DeepLearning-MLP.ipynb}
   \item
    \textbf{8.2.DeepLearning-SRNN.ipynb} 
   \item
    \textbf{8.3.DeepLearning-LSTM.ipynb:}      

    Realizan experimentos específicos con modelos de Perceptrón Multicapa, Red Neuronal Recurrente Simple y Memoria a Corto y Largo Plazo, respectivamente.
    
   \item
    \textbf{8.4.DeepLearning-SRNN(SlidingWindows).ipynb}
   \item
    \textbf{8.5.DeepLearning-LSTM(SlidingWindows).ipynb:}
    
    Realizan experimentos específicos con modelos de Perceptrón Multicapa, Red Neuronal Recurrente Simple y Memoria a Corto y Largo Plazo,respectivamente pero añadiendo ventanas deslizantes.
    
   \item
    \textbf{9.1.ProcesadoAumentoDatosSmote.ipynb:} 
    
    Con smote aumenta y reparte con datos sintéticos la cantidad de datos para el análisis EEG. 
    
   \item
    \textbf{9.2.DeepLearning-SRNN(AumentoDatos).ipynb}
   \item
    \textbf{9.3.DeepLearning-LSTM(AumentoDatos).ipynb:}
    
    Implementa experimentos utilizando modelos KNN, Árboles de Decisión, Random Forest con validaciones como hold-out, k-fold cross validation ... pero con el aumento de la cantidad de datos con smote.
    
   \item
    \textbf{9.4.DeepLearning-SRNN(AumentoDatosSlidingWindows).ipynb}
   \item
   \textbf{ 9.5.DeepLearning-LSTM(AumentoDatosSlidingWindows).ipynb:} 
    
    Realizan experimentos específicos con modelos de Perceptrón Multicapa, Red Neuronal Recurrente Simple y Memoria a Corto y Largo Plazo,respectivamente pero añadiendo ventanas deslizantes y aumento de la cantidad de datos con smote.
    
   \item
    \textbf{10.Resultadosconjuntodatostest.ipynb:} 
    
    Recopila los resultados de los experimentos y los traslada a varias tablas.
   \end{itemize} 
  \end{itemize} 
  
  
\textbf{Requisitos de Software:} 

  \begin{itemize}
   \tightlist
   \item
    \textbf{Anaconda}: Para el desarrollo del trabajo he utilizado la solución completa de Anaconda así he evitado posibles dependencias a la hora de instalar Python o Jupyter Notebook deparados.
  \end{itemize}
  

Anaconda incluye su propia distribución de Python, por lo que al instalar Anaconda en el sistema, automáticamente se tendrá una instalación de Python junto con una serie de paquetes adicionales útiles para el análisis de datos y la programación científica.

En la ejecución del proyecto también se ejecuta un entorno virtual, al crear y activar un entorno virtual en el proyecto se obtienes los siguientes beneficios:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item Aíslo dependencias: Puedo instalar bibliotecas y paquetes específicos para el proyecto evitando conflictos entre versiones de paquetes.

\item Reproducibilidad: Se puede reproducir el entorno del proyecto en diferentes ordenadores sin pensar en las dependencias asociadas a los paquetes.

\item Facilidad de gestión: Se puede instalar, actualizar o eliminar paquetes sin afectar a otros proyectos o al sistema de Notebooks de Python.

\end{enumerate}


Para desarrollar este proyecto se ha utilizado la plataforma GitHub.
La descarga del repositorio se realizara de la siguiente manera:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item Acceder al repositorio GitHub \href{https://github.com/jpg1003/GII_O_MA_23.37}{Acceso repositorio Github}
\item Pulsar en Code. (Botón verde)
\item Y a continuación pulsar en Download zip.

\imagen{anexos/DownloadZip}{Descarga repositorio GitHub}

\item Llevar el archivo zip descargado a la carpeta que se quiera utilizar para acceder al repositorio.
\item Descomprimir el archivo zip con el nombre de carpeta que se desee.

\end{enumerate}

\section{Compilación, instalación y ejecución del proyecto}


Una vez descargado el repositorio en la carpeta del sistema operativo utilizado se ha de proceder a la instalación del software requerido. 

\textbf{Instalación de software requerido:} 
  \begin{itemize}
   \tightlist
   \item
    \textbf{Anaconda}: 
    \begin{itemize}
   \tightlist
   \item
    Ir al sitio web oficial de Anaconda en \href{https://www.anaconda.com/download/success}{Enlace url Anaconda}. 
   \item
    Descargar la versión más reciente de Python 3.x. para el sistema operativo compatible.
   \item
   Instalar el archivo descargado.
   \end{itemize}
  \end{itemize}  


Una vez instalado el paquete de aplicaciones Anaconda, en el sistema operativo aparecerá una aplicación llamada \textbf{Jupyter Notebook}:

Ejecutar la aplicación \textbf{Jupyter Notebook}, una vez iniciada, se abrirá un navegador de Internet (el que este predeterminado en el sistema operativo) y mostrara un explorador de archivos por el cual, tendrá que navegar hasta la carpeta descargada del repositorio Github, se debería ver algo parecido a esto:


\imagen{anexos/Listado-Notebooks}{Listado de Notebooks en Jupyter Notebook}


Para ejecutar el proyecto de estudio de datos EEG se puede hacer de dos maneras:

  \begin{itemize}
   
   \item
    \textbf{Automática}: 
    \begin{itemize}
   
   \item
    Abrir el archivo 1.Main.ipynb a través de Jupyter Notebook y ejecutar una a una las celdas de este notebook. No se deben ejecutar todas a la vez porque se necesita la interacción con el usuario para subir los datos de tipoEEG a analizar.
   \end{itemize}

    \textbf{Manual}: 
    \begin{itemize}
   
   \item
    Abrir y ejecutar cada uno de los notebooks a través de Jupyter Notebook. 
   \item
    Se ha de seguir la numeración marcada por cada uno de los Notebooks, obviando los notebooks 1.Main.ipynb y los que no tengan numeración.
   \end{itemize}   
   
  \end{itemize}  

Con la ejecución Automática los notebooks se ejecutaran en orden y se quedara toda la información en el mismo notebook.
Si fuera de manera Manual, se tendría más control de lo que se esta ejecutando al estar dividido el código de cada notebook en varias celdas, pero toda la información estaría dividida en cada uno de los notebooks y no en un solo lugar.



\section{Pruebas del sistema}


Se han realizado varias pruebas de clasificación con el sistema probando con varios modelos de aprendizaje automático:

\begin{itemize}
	\item
	\textbf{Pruebas simples con modelos:}

	Los resultados obtenidos para todos los modelos implementados (KNN, Arboles de decisión, Random Forest, MLP, RNN y LSTM) han sido los siguiente:
	
\imagen{memoria/TEST_comparador}{Ejemplo resultados Tasa de acierto primer experimento comparativo para subconjunto Test}{.9}	

	Las filas corresponden a los conjuntos de datos siguientes: 
	
	Segmento del 1 al 4 son conjuntos de datos individuales por sesión o condiciones experimentales. Comentados en la sección Diseño de datos / Division del conjunto de datos.
	
	All Segmentos after es un conjunto de datos que se crea después de haber sido escalados los segmentos individualmente y unificados en un solo conjunto de datos.

	All Segmentos before es un conjunto de datos que se crea escalando todo el conjunto de datos global sin haber escalado por separado los segmentos
	
	Las columnas de la tabla corresponden a los siguientes experimentos:
	
	KNN-TEST: Algoritmo de clasificación KNN y validación por Holdout.
	
	TREE-TEST: Algoritmo de clasificación por Arboles de decisión y validación por Holdout.

	RANDOM-TEST: Algoritmo de clasificación por random forest y validación por Holdout.

	MLP-TEST: Clasificación por red neuronal MLP.

	RNN-TEST: Clasificación por red neuronal RNN.

	LSTM-TEST: Clasificación por red neuronal LSTM.

	Se puede ver a simple vista que los resultados para la métrica Tasa de acierto no han sido buenos para cualquiera de los modelos comparados.

	Se han conseguido valores en Tasa de acierto de como máximo el 69,23 en uno de los segmentos individuales y del 36,76 en uno de los conjunto de datos completos.


	\item
	\textbf{Pruebas con aumento de datos:}
	
	La inclusión de datos sintéticos ha demostrado ser beneficioso para mejorar las tasas de acierto en comparación con el uso exclusivo de datos reales. 
	
	Este enfoque ha permitido aumentar la diversidad y la cantidad de datos disponibles para el entrenamiento, lo cual es crucial cuando los datos reales son limitados.
	
	
\imagen{memoria/TEST_sinteticos}{Ejemplo resultados Tasa de acierto experimento con aumento de datos a Test}{.6}

	Las columnas de la tabla corresponden a los siguientes experimentos:

	RNN-RS-TEST: Clasificación por red neuronal RNN con aumento de datos.

	LSTM-RS-TEST: Clasificación por red neuronal LSTM con aumento de datos.

	Estos resultados en comparación con los anteriores son un 10 por ciento mayores pero aun no son buenos resultados para la métrica Tasa de acierto.
	

	\item
	\textbf{Pruebas con ventanas deslizantes:}
	
	Los datos recogidos tras utilizar las ventanas temporales con datos reales y con el aumento de datos sintéticos han sido los siguientes:
	
\imagen{memoria/TEST_SW}{Ejemplo resultados Tasa de acierto experimento ventanas temporales a Test}{.6}

\imagen{memoria/TEST_SW_RS}{Ejemplo resultados Tasa de acierto experimento ventanas temporales con aumento de datos a Test}{.6}



	Las columnas de la tabla corresponden a los siguientes experimentos:

	RNN-SW-TEST: Clasificación por red neuronal RNN con ventanas deslizantes.

	LSTM-SW-TEST: Clasificación por red neuronal LSTM con ventanas deslizantes.

	RNN-RS-SW-TEST: Clasificación por red neuronal RNN con ventanas deslizantes y aumento de datos.

	LSTM-RS-SW-TEST: Clasificación por red neuronal LSTM con ventanas deslizantes y aumento de datos.

	
	El impacto combinado de las dos técnicas para el análisis hace que el aumento en el porcentaje de la tasa de acierto, para el conjunto de datos estandarizado por segmentos y luego unificado en un solo conjunto de datos, alcanza hasta el 83.64 por ciento.
	
	
	\item
	\textbf{Pruebas con aumento datos contra datos Reales:}


	La comparación directa entre conjuntos con aumento de datos y subconjuntos Test de exclusivamente datos reales ha llegado a mostrar que los resultados  pueden llegar a superar significativamente, el rendimiento de Tasa de acierto que de los que solo eran datos reales. 
	
	Esto sugiere que los datos sintéticos pueden capturar mejor la variabilidad inherente en las señales EEG y mejorar la capacidad de generalización de los modelos.
	
	Unificando de nuevo las técnicas de aumento de datos y ventanas deslizantes se ha llegado hasta el 64,17 por ciento en Tasa de Acierto, algo esperanzador para futuras líneas de investigación puesto que mejora en un casi 30 por ciento de Tasa de acierto con los modelos comparativos con solo datos reales.

\imagen{memoria/TEST_real}{Ejemplo resultados Tasa de acierto experimento aumento de datos a datos reales Test}{0.6}

	Las columnas de la tabla corresponden a los siguientes experimentos:

RNN-RS-TEST: Clasificación por red neuronal RNN con aumento de datos.

LSTM-RS-TEST: Clasificación por red neuronal LSTM con aumento de datos.

RNN-RS-SW-TEST: Clasificación por red neuronal RNN con ventanas deslizantes y aumento de datos.

LSTM-RS-SW-TEST: Clasificación por red neuronal LSTM con ventanas deslizantes y aumento de datos.


\end{itemize}





