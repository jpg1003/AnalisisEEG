\apendice{Especificación de diseño}

\section{Introducción}

La especificación de datos es un componente crítico en el desarrollo de sistemas de información, especialmente cuando se trabaja con conjuntos de datos complejos como los datos EEG. 

Mediante BCI, sistema que permite mediante adquisición de señales EEG, se han podido interpretar las señales adquiridas a través de las señales EEG y poder transformarlas en un conjunto de datos para su posterior análisis.  


\section{Diseño de datos}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\textbf{Descripción de los Datos:}

El archivo datosEEGTotal.csv contiene los datos facilitados para poder realizar los experimentos para la ejecución del TFG.

Su formato es de tipo CSV con un separador (;) entre los datos que lo componen.

Las características recogidas en el archivo de los datos EEG son las siguientes:

Timestamp, Attention, Meditation, Delta, Theta, LowAlpha, HighAlpha, LowBeta, HighBeta, LowGamma, HighGamma, Signal y Key.

\textbf{Timestamp:} Registro de tiempo para los experimentos, medido en mili-segundos.

\textbf{Attention:} Registra el grado de atención del participante que realiza el experimento.

\textbf{Meditation:} Grado de calma que tendría el individuo.

\textbf{Delta:} Son ondas de baja frecuencia (1 y 4 Hz), están presentes en etapas de sueño profundo, durante una meditación profunda y en pacientes con lesiones cerebrales o con TDAH severo.

\textbf{Theta:} Ondas entre 4 y 8 Hz, se encuentran en estados de calma profunda y sueño R.E.M., están ligadas al aprendizaje, memoria y intuición.

\textbf{Alpha:} Ondas entre 8 y 12 Hz, representan un estado de poca actividad cerebral y se asocian a un estado de calma mental. Divididas en dos señales LowAlpha y HighAplpha

\textbf{Beta:} Se diferencian en LowBeta y HighBeta, su frecuencia esta entre 12 y 35Hz, asociadas a una alta actividad mental. 

\textbf{Gamma:} En los datos se diferencia LowGamma y HighGamma, son ondas por encima de 30Hz y suelen aparecer cuando hay una alta concentración o atención

\textbf{Signal:} Podría ser la señal de que aporta la interfaz BCI.

\textbf{Key:} Valores target de lo que el individuo estaba pensando o visualizando durante el experimento.


La transformación de datos o el preprocesado que se ha realizado para poder afrontar los experimentos del TFG han sido los siguientes:


\textbf{Unificación de características Key:} El conjunto de datos tiene varios valores en Key que indican los mismo. LButton y Left.

\imagen{anexos/Key}{Cantidad de elementos para la característica Key}

\textbf{División del conjunto de datos:} El conjunto de datos tiene cuatro segmentos divididos por su Timestamp, superponiéndose entre ellos. Divido en estos cuatro segmentos para poder realizar experimentos y también dejo el conjunto de datos sin dividir para realizar experimentos conjuntos a los cuatro segmentos.

\imagen{anexos/Timestamp}{Análisis característica Timestamp del conjunto de datos}

\textbf{Eliminación de características:} Elimino las características Signal por no aportar nada significativo en el conjunto de datos y Timestamp porque no quiero que los datos aportados puedan tener una patrón temporal que haga que los experimentos no sean reales.

\textbf{Eliminación de outliners:} Elimino los outlines (datos atípicos) del conjunto de datos. Utilizo zcore con un umbral de 3. \href{https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule}{Regla del 68–95–99.7}


\textbf{Escalado de datos:} He utilizado la opción de escalar los datos ya que no son datos normales puesto que no tienen una distribución gaussiana en sus datos. En este trabajo con datos EEG, el diseño de datos consta de:

\item 
\textbf{Almacenamiento de datos:}

\begin{itemize}
   \tightlist
   \item
    \textbf{Almacenamiento temporal:}
    
    Durante el análisis, los DataFrames se almacenan en memoria.
    \item
    \textbf{Almacenamiento Permanente:}
    
    Los resultados intermedios o finales se guardan en archivos CSV o en otros formatos como keras para un acceso más eficiente.    
\end{itemize}        

\item 
\textbf{Modelo Entidad-Relación (ERD):}

\begin{itemize}
   \tightlist
   \item
    \textbf{Entidad: Archivo CSV}.
    
    Representa el archivo CSV cargado al sistema.
    
    \item
    \textbf{Entidad: Registro EEG.}
    
    Cada fila del CSV correspondiente a un registro de señales EEG que crearan el dataframe a analizar. 
    
    
    
    \item
    \textbf{Entidad: Preprocesado.}
    
    Representa la transformación necesaria para la ejecución de los modelos. 
    
 
    \item
    \textbf{Entidad Modelo.}
    
    Representa cada modelo entrenado por cada conjunto de datos. Los datos que se guardan son de tipo csv con los resultados de la métrica Tasa de acierto.
    
    
    \item
    \textbf{Entidad Resultado:.}
    
    Almacena los resultados obtenidos de los modelos.  
       
\end{itemize}
\end{enumerate}
\imagen{anexos/ERD}{Diagrama Entidad Relación}






\section{Diseño procedimental}

En este trabajo he utilizado notebooks Jupyter para analizar el conjunto de datos EEG, por este motivo el diseño arquitectónico resultante ha sido el siguiente:


\textbf{Arquitectura del Sistema:}

La idea principal era que la ejecución de varios modelos de machine y deep learning se pudieran ejecutar de una manera eficiente y que fueran independientes sus ejecuciones. 
Para esto, el diseño se compone de un notebook Jupyter que llama celda a celda a diferentes notebooks en los cuales se desarrolla el código a ejecutar. 

Los componentes principales son:

  \begin{itemize}
  \tightlist
  \item
   \textbf{Notebook principal}, desde el cual se orquesta todas las ejecuciones de los demás notebooks.
  \item
   \textbf{Notebooks secundarios preparatorios}, que como su nombre indica, preparan el entorno para que puedan ser ejecutados los experimentos.
  \item
   \textbf{Notebook subida datos en archivo CSV}, desde esta llamada se sube el archivo con el conjunto de datos a analizar.
  \item
   \textbf{Notebook secundarios para experimentos} donde se ejecutan los experimentos asociados al TFG.
  \item
   \textbf{Notebook de resultados} que imprime los resultados de tasa de acierto en los experimentos contra los datos de tipos test.
  \end{itemize}
 
 
 \imagen{anexos/modulos}{Diagrama de interacción entre módulos }
 
  

  \textbf{Manejo de datos y proprocesado:}

  \begin{itemize}
  \tightlist
  \item
   \textbf{Pandas:} Para la manipulación y análisis de datos estructurados en DataFrames.
  \item
   \textbf{NumPy:} Para operaciones numéricas eficientes en matrices, arrays y listas.
  \item
   \textbf{Scikit-learn y SciPy:} Para escalado de datos, transformación y técnicas de preprocesamiento como StandardScaler y z-score.
  \end{itemize}

  \textbf{Técnicas de validación:}

  \begin{itemize}
  \tightlist
  \item
   \textbf{Holdout:} División de los datos en conjuntos de entrenamiento, validación y prueba para evaluación inicial.
  \item
   \textbf{K-Fold Cross-Validation:} Validación cruzada con KFold para evaluar la variabilidad del modelo.
  \item
   \textbf{Leave-One-Out:} Validación de uno en uno los datos dejando los demás fuera, así se evalúa la robustez del modelo. 
  \end{itemize} 
  
  \textbf{Modelos de aprendizaje automático:}

  \begin{itemize}
  \tightlist
  \item
   \textbf{K-Nearest Neighbors (KNN):} Clasificación basada en la proximidad de los puntos de los datos.
  \item
   \textbf{Árboles de decisión (Decision Tree):} Utiliza una estructura de árbol para realizar predicciones basadas en decisiones binarias.
  \item
   \textbf{Random Forest:} Mejora la precisión y reduce el sobreajuste utilizando múltiples árboles de decisión.
  \end{itemize}   

  \textbf{Redes Neuronales y Modelos Avanzados:}

  \begin{itemize}
  \tightlist
  \item
   \textbf{Multi-Layer Perceptron (MLP):} Implementan redes neuronales feedforward. Esta arquitectura de red neuronal no tiene ciclos en sus conexiones neuronales sino que que los datos van en una dirección desde la capa de entrada a la capa de salida. Es el más básico.
  \item
   \textbf{Simple Recurrent Neural Network (SRNN):} Es un tipo básico de red neuronal que tiene conexiones recurrentes que le permite mantener y utilizar información previa en la secuencia de datos. Es muy parecida a MLP pero en este caso las conexiones entre neuronas si pueden ir hacia detrás.
  \item
   \textbf{Long Short-Term Memory (LSTM):} Es una red neuronal avanzada en comparación con la recurrente SRNN. La diferencia principal es que puede retener la información relevante durante mas tiempo que SRNN.
  \end{itemize} 


  \textbf{Técnicas para la creación de datos sintéticos:}

  \begin{itemize}
  \tightlist
  \item
   \textbf{SMOTE (Synthetic Minority Over-sampling Technique):} Uso de la biblioteca imblearn para crear ejemplos sintéticos.
  \end{itemize}   
  


\section{Diseño arquitectónico}

El sistema está diseñado de manera modular, con notebooks secundarios encargados de tareas específicas. El notebook principal orquesta la ejecución de los demás notebooks, asegurando que cada etapa del proceso se complete antes de pasar a la siguiente. Los datos y resultados se almacenan de manera eficiente para facilitar su análisis y reutilización.

Este diseño integral garantiza una gestión y análisis de datos estructurados y eficientes, facilitando el desarrollo y la evaluación de modelos predictivos para datos EEG. Además, cada notebook secundario puede ejecutarse de manera independiente siguiendo un orden predefinido, lo que ofrece flexibilidad en la realización de análisis específicos o la repetición de etapas del proceso según sea necesario.

Esta adición enfatiza la versatilidad del sistema al permitir ejecuciones independientes de los notebooks secundarios, mientras se mantiene la integridad y la eficiencia del flujo de trabajo general.

La organización del sistema seria de esta manera:


 \imagen{anexos/esquema}{Organización del sistema}

