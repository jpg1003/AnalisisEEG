\apendice{Plan de Proyecto Software}

\section{Introducción}

La Universidad de Burgos, dentro del área de conocimiento de Ingeniería de Sistemas y Automática, dispone de un interfaz BCI (Brain Computer Interface) para la captación de señales cerebrales. 
Empleando ese interfaz se han realizado diferentes experimentos que han permitido recoger información de la actividad cerebral mientras los usuarios ejecutaban diferentes tareas cotidianas. 

Este Trabajo de Fin de Grado (TFG) tiene como objetivo principal el análisis de la información obtenida en esos experimentos. Se entrenarán diferentes algoritmos para clasificar la acción realizada por el usuario a partir de las señales generadas por el BCI. Con este propósito, se evaluarán diferentes algoritmos de procesado de señales y de machine/deep learning para la clasificación automática de señales.

El conjunto de datos para la realización del TFG son de tipo EEG (Electroencefalografía) referentes a experimentos basados en acciones sobre teclas de un teclado: arriba, abajo, izquierda, derecha.

El análisis de estos datos y su evaluación en diferentes algoritmos está basada en predecir qué teclas del teclado se han pulsado según las señales captadas con la interfaz BCI.



\section{Planificación temporal}


En la reunión inicial con los tutores definimos utilizar Python como lenguaje de programación para escribir el código y una serie de cursos de aprendizaje básicos para poder acometer el TFG sin problemas.

En las siguientes reuniones se definieron algoritmos y experimentos a realizar con los datos EEG recogidos.


Desde el inicio del proyecto se ha utilizado la herramienta GitHub para ir subiendo todo el código o documentación realizada vía commits al repositorio creado para el proyecto ~\cite{github:proyecto}, a continuación se muestra la linea temporal durante la elaboración del proyecto:

\imagen{anexos/Commits1}{Commits realizados durante la realización del TFG}

\imagen{anexos/Additions1}{Additions realizados durante la realización del TFG}

\imagen{anexos/Deletions1.png}{Deletions realizados durante la realización del TFG}


El desarrollo de este proyecto siguió la metodología CRISP-DM (Cross Industry Standard Process for Data Mining) ~\cite{wiki:CRISP}, un enfoque estructurado y bien establecido para proyectos de minería de datos y análisis predictivo. 

A continuación, se detallan los aspectos más interesantes y relevantes de cada fase del ciclo de vida del proyecto según CRISP-DM.


\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}	
\item
\textbf{Comprensión del Negocio}

El objetivo principal fue identificar los objetivos y requisitos del proyecto desde una perspectiva empresarial.

Se llevaron a cabo reuniones con los tutores para entender los objetivos específicos del proyecto, como la detección y clasificación de acciones de movimiento (arriba, abajo, derecha, izquierda).

Se establecieron metas claras y medibles para el sistema de análisis de señales EEG, incluyendo los modelos a utilizar.

En esta fase se tomo la decisión de crear un modelo modular con un Notebook Principal que realizara llamadas al resto de Notebooks secundarios siguiendo los objetivos de negocio de poder ser escalables para futuras investigaciones.


\item
\textbf{Comprensión de los Datos}

Unos de los objetivos principales fue familiarizarme con los datos disponibles y realizar un análisis preliminar.

Hubo una exploración inicial donde se exploro los conjuntos de datos EEG para comprender su estructura, características y distribución.

Se hizo uso de herramientas y visualizaciones para identificar patrones y posibles anomalías en los datos.

Se identificaron valores atípicos (outliners) que podrían afectar negativamente el rendimiento de los modelos.

Se realizaron cursos online básicos propuestos en las reuniones de seguimiento:
Tutorial de Inicio de Pandas~\cite{curso:a}, Visualización de Datos~\cite{curso:b}, Trabajo con series temporales.~\cite{curso:c}

\item
\textbf{Preparación de los Datos}

El objetivo principal de esta fase es preprocesar y preparar los datos para su análisis en los diferentes modelos.

En esta fase se crearon nuevos conjuntos de datos para luego realizar análisis sobre ellos. En total 6 como se ha descrito con anterioridad.

Se aplicación de técnicas de normalización y escalado, como StandardScaler y Z-Score, para estandarizar las señales EEG.

Creación y utilización de ventanas deslizantes, agrupándolas por cada uno de los tipos de datos de cada conjunto de datos generado.

Al final de la fase se propuso la generación de Datos Sintéticos para aumentar la cantidad y diversidad del conjunto de datos y abordar el análisis de los modelos desde otra perspectiva.

\item
\textbf{Fase de Modelado}

El objetivo en esta fase fue seleccionar y aplicar técnicas de modelado adecuadas. Los que se han utilizado para el proyecto son los siguientes:

	\begin{itemize}
	
	\item
	\textbf{Algoritmos de Machine Learning:}

	K-Nearest Neighbors (KNN)
	Árboles de Decisión
	Random Forest

	\textbf{Evaluación y Comparación:}
	Uso de métricas como Tasa de acierto y loss para evaluar el rendimiento de estos modelos.

	\textbf{Redes Neuronales:}
	Multilayer Perceptron (MLP)
	Redes Neuronales Recurrentes (RNN)
	Long Short-Term Memory (LSTM)

	\textbf{Optimización y Regularización:} 

	Uso de técnicas como Dropout para mejorar la generalización de los modelos.
	\end{itemize}


Las dificultades que se encontraron en esta etapa fueron:

\textbf{- Compilación de modelos de redes neuronales. }

	Al ejecutar los primeros modelos de redes neuronales los datos normalizados me proporcionaban errores de compilación con modelos SRNN o LSTM, tuve que cambiar el escalado de los datos datos y shapear los modelos para que pudieran ejecutarse.

\textbf{- Utilización de ventanas temporales en los modelos de redes neuronales.} 

	En esta etapa no supe identificar este requerimiento por parte de los tutores y estuve implementando varias formas de poder utilizar ventanas temporales en el código, esto hizo que tuviera un gran retraso en la finalización y aceptación del codigo.

\textbf{- Utilización de modelos de redes neuronales y callbacks.} 

	El sobreajuste en los modelos predictivos era una constante y se implemento el uso de callbacks para evitar este sobreajuste.


\textbf{- Gráficas y definiciones básicas como normalizar o escalar el conjunto de datos.}



\item
\textbf{Evaluación}


En esta fase se trata de poder evaluar el modelo para asegurar que cumple con los objetivos del negocio. Para ellos se utilizaran las siguientes técnicas:


	\begin{itemize}
	
	\item
	\textbf{Métricas de Evaluación:}

Para todos los modelos se ha utilizado la evaluación mediante subconjuntos de datos de validación y prueba. (Val y Test)

	\item
	\textbf{Utilización de Callbacks y Técnicas de Monitorización:}

 Se ha hecho uso de EarlyStopping, ReduceLROnPlateau y ModelCheckpoint para evitar el sobreajuste y guardar el mejor modelo durante el entrenamiento.
	\end{itemize}


\item
\textbf{Despliegue}

En esta fase el objetivo es la implementacion del proyecto y para ello se empezó con la definición y creación de los primeros Jupyter Notebooks.


\textbf{Jupyter Notebooks.} 

Se han utilizado no solo para el desarrollo iterativo y la experimentación rápida, sino también para la implementación modular del proyecto. 

La capacidad de crear, documentar y ejecutar celdas de código de manera interactiva permite a los usuarios finales poder ajustar y probar el proyecto en tiempo real, facilitando la depuración y el ajuste fino.

La naturaleza modular de los Jupyter Notebooks ha permitido separar distintas fases del proceso, desde la carga y preprocesamiento de datos hasta el entrenamiento y evaluación del modelo. 

Esta separación ha facilitado el mantenimiento y la actualización de cada componente sin afectar al resto del sistema.

\end{enumerate}





\section{Estudio de viabilidad}


\subsection{Viabilidad económica}

La viabilidad económica evalúa la posibilidad de generar ingresos y recuperar la inversión realizada a través del proyecto desarrollado. Se han de considerar las siguientes áreas:
\begin{itemize}
\tightlist
   \item
    \textbf{Potencial del proyecto para Otros BCIs:} 
    
    El código desarrollado para el análisis de señales EEG podría adaptarse y aplicarse a una variedad de sistemas BCI disponibles en el mercado. La flexibilidad del lenguaje de programación Python permite su integración con sistemas existentes, ampliando su potencial de mercado.
    
   \item
    \textbf{Mercado Objetivo:} 
    
    Los fabricantes de sistemas BCI constituyen el mercado principal para la comercialización del software desarrollado. Ejemplos de fabricantes incluyen NeuroSky, Emotiv, Brain Products y otros proveedores de dispositivos de interfaz cerebro-ordenador utilizados en investigación, medicina y aplicaciones comerciales. En España destacan Starlab Barcelona, Bitbrain, Neuroelectrics y Starlab.
    
   \item
    \textbf{Modelo de Negocio:} 
    
    Se propone un modelo de negocio basado en licencias de software. Los fabricantes de BCI podrían adquirir licencias comerciales del software para integrarlo en sus productos o servicios. Las licencias podrían estructurarse en diferentes niveles de funcionalidad y soporte, permitiendo adaptarse a las necesidades específicas de cada fabricante.
    
   \item
    \textbf{Estrategia de Comercialización:}
    
    La estrategia de comercialización incluiría demostraciones técnicas, pruebas piloto y colaboraciones estratégicas con fabricantes de BCI. Se realizarían  participaciones y colaboraciones en conferencias y eventos de la industria, así como la utilización de plataformas online para promover el software y captar el interés de potenciales clientes.

\end{itemize}




\subsection{Viabilidad legal}


Tipos de licencias para el sofware y bibliotecas instalado:

\begin{itemize}
 \tightlist
  \item
   \textbf{BSD (Berkeley Software Distribution):} 
    
    BSD es una licencia permisiva de código abierto que permite el uso, modificación y distribución del software con pocas restricciones. Requiere que se mantengan los avisos de copyright y las cláusulas de la licencia..
    
  \item
   \textbf{ASF (Apache Software License):}
    
    ASF 2.0 permite el uso, modificación y distribución del software, otorgando derechos de patente explícitos. Requiere mantener los avisos de copyright y proporcionar una NOTIFICACIÓN de cambios significativos.
    
  \item
   \textbf{Código abierto (Open source):}
    
    Las licencias de código abierto permiten el acceso, uso, modificación y distribución libre del software. Estas licencias fomentan la colaboración y la transparencia en el desarrollo de software, garantizando la libertad de uso y mejora.
\end{itemize}



El estudio de viabilidad ha demostrado que el desarrollo del software de análisis de datos EEG presenta una sólida oportunidad económica y cumple con los requisitos legales necesarios para su comercialización.

La aplicación potencial del software a otros sistemas BCI y la flexibilidad del modelo de negocio basado en licencias ofrecen un camino claro hacia la monetización y la expansión del proyecto.

  A continuación se presenta una tabla con algunas de las principales bibliotecas y herramientas de software utilizadas en el proyecto, junto con el tipo de licencia y las restricciones asociadas:
 

\begin{table}[p]
	\centering
	\begin{tabularx}{\linewidth}{ p{0.3\columnwidth} p{0.3\columnwidth} p{\columnwidth}}
		\toprule
		\textbf{Software}    & \textbf{Licencia} & \textbf{Restricciones} \\
		\toprule		
		\textbf{Anaconda}              & Gratuita    & Uso personal.  \\
		\toprule	
		\textbf{Jupyter Notebook}              & Libre    & Código abierto \\
		\toprule			
		\textbf{Python}              & Libre permisiva    & BSD \\
		\toprule		
		\textbf{Numpy}              & Libre permisiva    & BSD \\
		\toprule		
		\textbf{Scipy}              & Libre permisiva    & BSD \\
		\toprule		
		\textbf{Pandas}               & Libre permisiva    & BSD \\
		\toprule		
		\textbf{Matplotlib}              & Libre permisiva    & BSD \\
		\toprule		
		\textbf{Seaborn}              & Libre permisiva    & BSD \\
		\toprule		
		\textbf{Sklearn}               & Libre permisiva    & BSD \\
		\toprule		
		\textbf{Tensorflow}              & Libre permisiva    & ASF \\
		\toprule		
		\textbf{Ipywidgets}              & Libre    & Código abierto \\
		\bottomrule
	\end{tabularx}
	\caption{Licencias Software}
\end{table}