\apendice{Plan de Proyecto Software}

\section{Introducción}


La ejecución de este proyecto se llevó a cabo siguiendo el método CRISP-DM (Cross-Industry Standard Process for Data Mining), un marco estructurado que guió todas las etapas del proceso. 

Desde la comprensión inicial del problema hasta la implementación final de la solución, cada fase fue cuidadosamente planificada y ejecutada.

Para la realización del proyecto no ha habido una planificación como tal registrada en Github, pero sí una progresión definida en los commits de código generados durante la composición del TFG.


\section{Planificación temporal}


En la reunión inicial con los tutores definimos utilizar Python como lenguaje de programación para escribir el código y una serie de cursos de aprendizaje básicos para poder acometer el TFG sin problemas.

En las siguientes reuniones se definieron algoritmos y experimentos a realizar con los datos EEG aportados.

Desde el principio del proyecto debido a circunstancias personales no se ha podido realizar metodología Scrum, pero siguiendo el método CRISP-DM (Cross-Industry Standard Process for Data Mining) se produjeron estas lineas temporales:

\imagen{anexos/Commits1}{Commits realizados durante la realización del TFG}

\imagen{anexos/Additions1}{Additions realizados durante la realización del TFG}

\imagen{anexos/Deletions1.png}{Deletions realizados durante la realización del TFG}


Se pueden dividir en 3 grandes etapas:

\begin{itemize}
\tightlist
\item
	\textbf{Fase de comprensión del Negocio y compresión de los datos: (Febrero a Marzo)}   	
\item
 	\textbf{Fase de modelado y Fase de evaluación: (Abril a Mayo)} 
\item
	\textbf{Fase de Evaluación y despliegue: (Junio a Julio)} 
\end{itemize}



\subsection{Fase de comprensión del Negocio y compresión de los datos: (Febrero a Marzo)}


\imagen{anexos/Commits-Etapa1}{Commits-Etapa 1}


\textbf{- Realización de cursos online:} 

Se han realizado cursos online básicos propuestos en las reuniones de seguimiento:
Tutorial de Inicio de Pandas~\cite{curso:a}, Visualización de Datos~\cite{curso:b}, Trabajo con series temporales.~\cite{curso:c}

\textbf{- Análisis del conjunto de datos}, en archivo csv, proporcionado por los tutores.

\textbf{- Creación esqueleto para la estructura el TFG en Github.}

\textbf{- Definición y creación de los primeros notebooks, principalmente análisis del conjunto de datos.}

\textbf{- Definición y creación de los primeros notebooks de machine learning}, al final de la etapa.

\textbf{- Comentar código e imprimir comentarios en los notebooks.}

Los principales problemas o obstáculos que me encontré fueron principalmente los siguientes:

\textbf{- Tiempo invertido en la realización de los cursos.}

\textbf{- Estructuración del código.} 

Me tomo mucho tiempo poder llegar a definir como quería mostrar el código, me decidí por un notebook principal que realizara llamadas al resto de notebooks con códigos mas específicos para cada modelo o experimento a realizar.

\textbf{- Impresiones de gráficas y definiciones básicas como normalizar o escalar el conjunto de datos.}


\subsection{Tabla de tiempos }


\tablaSmallSinColores{Tabla de tiempos para las primeras fases}{l c}{Tabladetiempos1}
{ \multicolumn{1}{l}{Actividad} & Estimación temporal \\}{ 
Curso Tutorial de Inicio de Pandas & 6 horas\\
Curso Visualización de Datos &  5 horas\\
Curso Trabajo con series temporales & 5 horas\\
Analisis datos & 25 horas \\
Definir estructura notebooks & 5 horas\\
Pruebas de impresión & 7 horas \\
Inicio Preprocesado & 30 horas\\
Inicio Machine Learning & 20 horas \\
Total & 103 horas \\
} 


\subsection{Fase de modelado y Fase de evaluación: (Abril a Mayo)}


\imagen{anexos/Commits-Etapa2}{Commits-Etapa 2}

\textbf{- Cambio de análisis del conjunto de datos, prepocessing.}

\textbf{- Definición y creación notebooks de machine learning.}

\textbf{- Definición y creación notebooks de deep learning.}


Los problemas que me encontré en esta etapa fueron:

\textbf{- Compilación modelos deep learning. }Al ejecutar los primeros modelos de deep learning los datos normalizados me proporcionaban errores de compilación con modelos SRNN o LSTM, cambiando a datos escalados y shapeando los modelos pudieron ejecutarse.

\textbf{- Utilización de ventanas temporales en los modelos deep learning.} En esta etapa no supe identificar este requerimiento por parte de los tutores y estuve implementando varias formas de poder utilizar ventanas temporales en el código.

\textbf{- Utilización de modelos deep learning y callbacks.} 

\textbf{- Gráficas y definiciones básicas como normalizar o escalar el conjunto de datos.}





\tablaSmallSinColores{Tabla de tiempos para las segundas fases}{l c}{Tabladetiempos2}
{ \multicolumn{1}{l}{Actividad} & Estimación temporal \\}{ 
Cambio en el preprocesado & 20 horas\\
Modelos Machine Learning &  25 horas\\
Modelos Deep Learning & 52 horas\\
Ventanas Temporales & 12 horas \\
Callbacks & 6 horas\\
Pruebas de impresión & 8 horas \\
Total & 123 horas \\
} 



\subsection{Fase de Evaluación y despliegue: (Junio a Julio)}


\imagen{anexos/Commits-Etapa3}{Commits-Etapa 3}

\textbf{- Añado nuevos gráficos} en análisis del conjunto de datos, prepocessing.

\textbf{- Definición y creación ventanas temporales acordadas con Bruno Baruque.}

\textbf{- Definición y creación nuevos notebooks de deep learning}

\textbf{- Definición y creación nuevos datos sintéticos a través de el aplicativo smote.}

\textbf{- Continuar con el comentado del código e imprimir comentarios en los notebooks.}


En la última etapa los problemas que se han acontecido son:

\textbf{- - Utilización de ventanas temporales en los modelos deep learning.} Después de varias algunas reuniones con Bruno Baruque se llego a la definición correcta para las ventanas temporal en el conjunto de datos.

\textbf{- Utilización de modelos deep learning y callbacks.}

\textbf{- Utilización datos sintéticos.} Definir correctamente esta generación de datos y poder utilizarlos en los modelos deep learning correctamente.


\tablaSmallSinColores{Tabla de tiempos para las ultimas fases}{l c}{Tabladetiempos3}
{ \multicolumn{1}{l}{Actividad} & Estimación temporal \\}{ 
Modelos Deep Learning & 40 horas\\
Ventanas Temporales & 8 horas \\
Datos sintéticos & 12 horas\\
Pruebas de impresión & 3 horas \\
Documentación & 72 horas \\
Total & 135 horas \\
} 


\textbf{En este proyecto el tiempo dedicado ha sido de 361 horas.}


\subsection{Releases}


\subsection{Release 1.0}

En esta primera release el codigo era funcional pero no se llego a un acuerdo para la utilizacion de ventanas temporales.

El código consta de varias fases: Análisis de datos, Preprocessing de datos, Machine Learning y Deep Learning.
En Deep Learning es donde no acabamos de aprobar un código para terminar de cerrarlo y poder entregarlo.

Hasta ahora los datos aportados en Machine Learning son muy positivos dando tasas de acierto mayores de 90 por ciento (Esto luego se demostró que no era real), pero en cambio para Deep Learning lo máximo que aportan los modelos es de una tasa de acierto del 50 por ciento.

Estamos conversando en como aplicar ventanas deslizantes en el análisis de los datos, pero puede que estos datos sean de una extensión muy pequeña para que los modelos LSTM o RNN puedan procesarlos correctamente y llegar a aprender y no memorizar datos, hasta ahora en los entrenamientos el modelo empieza a realizar sobreajuste a los pocos epochs de empezar el entrenamiento.

Los siguientes pasos serian: poder cerrar el código, revisión y limpieza de código, conclusiones, crear la memoria con todos los cambios.

\subsection{Release 2.0}

En esta release se llegó a un acuerdo para el código entre los tutores y yo.

El código consta de varias fases: Análisis de datos, Preprocessing de datos, Machine Learning y Deep Learning.
En Deep Learning ya se llego al acuerdo de implementar Ventanas Temporal asociadas a solo un target por ventana y utilizando stratify.

En la reunión también salió un nuevo experimento con datos sintéticos que ya están implementados en esta release.
Los porcentajes aportados para tasa de acierto en Machine Learning y Deep Learning son inferiores al 50 por ciento pero con aumento de datos con smote podemos llegar a tasas de acierto mas esperanzadoras.

Los siguientes pasos serian: revisar y seguir comentando lo que quede del nuevo código, limpieza de código, crear memoria y anexo con todos los cambios.

\subsection{Release 3.0}

En esta release se modifica el modelo MLP y se empieza a documentar la memoria y los anexos.

Esta release contiene todos los apartados comentados en la releases anteriores.

Esta igual que las otras releases es una version totalmente funcional.


\subsection{Release 4.0}

En esta ultima release se limpian los comentarios en los Notebooks y se completa la documentación en latex de los archivos memoria y anexos. También se realiza limpieza de código.

Esta release contiene todos los apartados comentados en la releases anteriores.

Esta release es la version definitiva.

\section{Estudio de viabilidad}


\subsection{Viabilidad económica}

La viabilidad económica evalúa la posibilidad de generar ingresos y recuperar la inversión realizada a través del proyecto desarrollado. Se han de considerar las siguientes áreas:
\begin{itemize}
\tightlist
   \item
    \textbf{Potencial del proyecto para Otros BCIs:} 
    
    El código desarrollado para el análisis de señales EEG podría adaptarse y aplicarse a una variedad de sistemas BCI disponibles en el mercado. La flexibilidad del lenguaje de programación Python permite su integración con sistemas existentes, ampliando su potencial de mercado.
    
   \item
    \textbf{Mercado Objetivo:} 
    
    Los fabricantes de sistemas BCI constituyen el mercado principal para la comercialización del software desarrollado. Ejemplos de fabricantes incluyen NeuroSky, Emotiv, Brain Products y otros proveedores de dispositivos de interfaz cerebro-ordenador utilizados en investigación, medicina y aplicaciones comerciales. En España destacan Starlab Barcelona, Bitbrain, Neuroelectrics y Starlab.
    
   \item
    \textbf{Modelo de Negocio:} 
    
    Se propone un modelo de negocio basado en licencias de software. Los fabricantes de BCI podrían adquirir licencias comerciales del software para integrarlo en sus productos o servicios. Las licencias podrían estructurarse en diferentes niveles de funcionalidad y soporte, permitiendo adaptarse a las necesidades específicas de cada fabricante.
    
   \item
    \textbf{Estrategia de Comercialización:}
    
    La estrategia de comercialización incluiría demostraciones técnicas, pruebas piloto y colaboraciones estratégicas con fabricantes de BCI. Se realizarían  participaciones y colaboraciones en conferencias y eventos de la industria, así como la utilización de plataformas online para promover el software y captar el interés de potenciales clientes.

\end{itemize}

\textbf{Costes del desarrollo del proyecto:}


\tablaSmallSinColores{Costes del desarrollo}{l c}{Tabladetiempos3}
{ \multicolumn{1}{l}{Concepto} & Tarifa en euros\\}{ 
Personal & \\ 2500 euros
Equipo informático & 2500 euros \\
Infraestructura & 500 euros\\
Total & 5500 euros \\
} 

\subsection{Viabilidad legal}


Tipos de licencias para el sofware y bibliotecas instalado:

\begin{itemize}

  \item
   \textbf{BSD (Berkeley Software Distribution):} 
    
    BSD es una licencia permisiva de código abierto que permite el uso, modificación y distribución del software con pocas restricciones. Requiere que se mantengan los avisos de copyright y las cláusulas de la licencia..
    
  \item
   \textbf{ASF (Apache Software License):}
    
    ASF 2.0 permite el uso, modificación y distribución del software, otorgando derechos de patente explícitos. Requiere mantener los avisos de copyright y proporcionar una NOTIFICACIÓN de cambios significativos.
    
  \item
   \textbf{Código abierto (Open source):}
    
    Las licencias de código abierto permiten el acceso, uso, modificación y distribución libre del software. Estas licencias fomentan la colaboración y la transparencia en el desarrollo de software, garantizando la libertad de uso y mejora.
\end{itemize}


El estudio de viabilidad ha demostrado que el desarrollo del software de análisis de datos EEG presenta una sólida oportunidad económica y cumple con los requisitos legales necesarios para su comercialización.

La aplicación potencial del software a otros sistemas BCI y la flexibilidad del modelo de negocio basado en licencias ofrecen un camino claro hacia la monetización y la expansión del proyecto.

  A continuación se presenta una tabla con algunas de las principales bibliotecas y herramientas de software utilizadas en el proyecto, junto con el tipo de licencia y las restricciones asociadas:


\tablaSmall{Licencias Software}{l c c}{LicenciasSoftware}
{ \multicolumn{1}{l}{l}{Software} & Licencia & Restricciones \\}{ 	
\textbf{Anaconda}              & Gratuita    & Uso personal.  \\
\textbf{Jupyter Notebook}              & Libre    & Código abierto \\		
\textbf{Python}              & Libre permisiva    & BSD \\	
\textbf{Numpy}              & Libre permisiva    & BSD \\	
\textbf{Scipy}              & Libre permisiva    & BSD \\		
\textbf{Pandas}               & Libre permisiva    & BSD \\		
\textbf{Matplotlib}              & Libre permisiva    & BSD \\		
\textbf{Seaborn}              & Libre permisiva    & BSD \\		
\textbf{Sklearn}               & Libre permisiva    & BSD \\		
\textbf{Tensorflow}              & Libre permisiva    & ASF \\		
\textbf{Ipywidgets}              & Libre    & Código abierto \\
}


Para recuperar la inversión estimada de 5500 euros y garantizar la viabilidad económica del proyecto, se puede optar por vender licencias de software con diferentes niveles de funcionalidad y soporte. 

Esta sería una propuesta para estructurar las licencias y sus costes:

\begin{itemize}

  \item
   \textbf{Licencia Básica:}

Descripción: Incluye acceso al estudio con funcionalidades básicas de análisis de señales EEG.

Soporte: Limitado a soporte por correo electrónico.

Coste: 100 euros por licencia.


  \item
   \textbf{Licencia Profesional:}


Descripción: Incluye todas las funcionalidades de la Licencia Básica, más características avanzadas de análisis y procesamiento de datos.

Soporte: Soporte técnico por correo electrónico y acceso a actualizaciones menores.

Coste: 500 euros por licencia.


  \item
   \textbf{Licencia Empresarial:}

Descripción: Incluye todas las funcionalidades de la Licencia Profesional, integración con otros tipos de modelos que se quieran utilizar y soporte para proyectos a gran escala.

Soporte: Soporte técnico completo, incluyendo asistencia telefónica y acceso a todas las actualizaciones.

Coste: 2500 euros por licencia.


Si se llega a publicitar correctamente este software podría ser altamente rentable si se llega a profesionalizar hacia licencias empresariales.

\end{itemize}